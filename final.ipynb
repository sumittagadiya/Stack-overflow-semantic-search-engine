{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1y5n7SVBSRv7SHbK9Hl0nBOUJLlixOhi-","authorship_tag":"ABX9TyOlERU+tdIiZaUQ26pu4ojS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rW-Y2lR6NBmG"},"source":["# In this notebook i will make final fucntion which takes user query and gives top 10 most similar results."]},{"cell_type":"markdown","metadata":{"id":"i4y1bNl2NO6U"},"source":["## we have tried different embedding techniques in preprocessing_sc1.ipynb and we have found that Universal sentence encoder gives most similar results so that we will use universal sentence encoding model "]},{"cell_type":"code","metadata":{"id":"vODqXytVgO2m","executionInfo":{"status":"ok","timestamp":1604157054331,"user_tz":-330,"elapsed":3601,"user":{"displayName":"sumit patel","photoUrl":"","userId":"08527105377083185844"}},"outputId":"bd5fc935-7331-478a-92f3-b3d81c971630","colab":{"base_uri":"https://localhost:8080/"}},"source":["import pandas as pd\n","import joblib\n","import numpy as np\n","import re\n","import time\n","from sklearn.metrics.pairwise import cosine_similarity\n","import os\n","import tensorflow_hub as hub\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s8mqk_9LgOv5","executionInfo":{"status":"ok","timestamp":1604078214313,"user_tz":-330,"elapsed":15388,"user":{"displayName":"sumit patel","photoUrl":"","userId":"08527105377083185844"}},"outputId":"9f37ea2d-8202-4c31-a1db-4a11473c11e6","colab":{"base_uri":"https://localhost:8080/"}},"source":["df = pd.read_csv('/content/drive/My Drive/self_case_study1/data/featurized_data.csv')\n","df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(425167, 10)"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"3f7pyXzeg_1w","executionInfo":{"status":"ok","timestamp":1604078293692,"user_tz":-330,"elapsed":1547,"user":{"displayName":"sumit patel","photoUrl":"","userId":"08527105377083185844"}},"outputId":"a94d1b6a-f611-4708-a0db-a25c21e60a9a","colab":{"base_uri":"https://localhost:8080/"}},"source":["from sklearn.model_selection import train_test_split\n","X_train,X_test = train_test_split(df,test_size=0.5,random_state=42)\n","\n","# reset index of train and test\n","X_train.reset_index(drop=True,inplace=True)\n","X_test.reset_index(drop=True,inplace=True)\n","\n","print('Shape of X_train',X_train.shape)\n","print('Shape of X_test',X_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of X_train (212583, 10)\n","Shape of X_test (212584, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HtMx69exg_6C","executionInfo":{"status":"ok","timestamp":1604078377804,"user_tz":-330,"elapsed":8673,"user":{"displayName":"sumit patel","photoUrl":"","userId":"08527105377083185844"}},"outputId":"ad381774-9792-42d2-8948-0e52e2c6e75d","colab":{"base_uri":"https://localhost:8080/"}},"source":["joblib.dump(X_train,'/content/drive/My Drive/self_case_study1/data/X_train.pkl')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/My Drive/self_case_study1/data/X_train.pkl']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"6AYINfwRMOVx","executionInfo":{"status":"ok","timestamp":1604157072134,"user_tz":-330,"elapsed":1234,"user":{"displayName":"sumit patel","photoUrl":"","userId":"08527105377083185844"}}},"source":["# below mentioned functions are helper functions which is use for text preprocessing\n","def decontracted(phrase):\n","    # specific\n","    phrase = re.sub(r\"won't\", \"will not\", phrase)\n","    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n","\n","    # general\n","    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n","    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n","    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n","    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n","    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n","    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n","    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n","    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n","    phrase = re.sub(r\"\\n\", \"\", phrase)\n","    return phrase\n","\n","stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n","            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n","            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n","            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n","            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n","            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n","            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n","            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n","            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n","            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n","            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n","            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n","            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n","            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n","            'won', \"won't\", 'wouldn', \"wouldn't\"])\n","\n","def remove_stopwords(text):\n","    '''this function will remove stopwords from text '''\n","    final_text = ''\n","    for word in text.split():\n","        if word not in stopwords:\n","            final_text += word + ' '\n","    return final_text\n","\n","def preprocess_title(text):\n","    # convert to lower case\n","    text = text.lower()\n","    # decontract\n","    text = decontracted(text)\n","    # remove all punctuations except a-z and c# and c++\n","    text = re.sub('[^a-zc#c++]+',' ',text)\n","    # remove stop words\n","    text = remove_stopwords(text)\n","    return text"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrgXiuB5XiL2","executionInfo":{"status":"ok","timestamp":1604158006525,"user_tz":-330,"elapsed":2796,"user":{"displayName":"sumit patel","photoUrl":"","userId":"08527105377083185844"}}},"source":["tf.logging.set_verbosity(tf.logging.ERROR)\n","# load universal sentence encoder\n","embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n","def embed_text(sentences):\n","    ''' This function will convert sentence into vector using universal sentence encoder'''\n","    # Reduce logging output.\n","    tf.logging.set_verbosity(tf.logging.ERROR)\n","    with tf.Session() as session:\n","        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n","        # create vectors from sentences\n","        embeddings = session.run(embed(sentences))\n","        # return  embeddings\n","        return embeddings"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTzqulRuhdGl","executionInfo":{"status":"ok","timestamp":1604157820418,"user_tz":-330,"elapsed":4205,"user":{"displayName":"sumit patel","photoUrl":"","userId":"08527105377083185844"}}},"source":["# load X_train\n","X_train = joblib.load('/content/drive/My Drive/self_case_study1/data/X_train.pkl')\n","# load question embedding trained using universal sentence encoder\n","question_embeddings = joblib.load('/content/drive/My Drive/self_case_study1/data/universal_embed/universal_question_embedding.pkl')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"UnqzTRLhO5xw","executionInfo":{"status":"ok","timestamp":1604158330149,"user_tz":-330,"elapsed":1248,"user":{"displayName":"sumit patel","photoUrl":"","userId":"08527105377083185844"}}},"source":["def final_func1(question,top_n=10):\n","    ''' This function will find top similar result for given query using universal sentence encoder'''\n","    start = time.time()\n","    # preprocess question\n","    question = preprocess_title(question)\n","    # initialize  vector for user query\n","    query_vector = embed_text([question])\n","    similarities =  cosine_similarity((query_vector).reshape(1, -1), Y=question_embeddings, dense_output=True)\n","    # sort similarities \n","    sort = np.argsort(similarities[0])\n","    # get top similarity indices  in descending order\n","    similarity_index = np.array(list(reversed(sort)))\n","    # find top n similarities\n","    top_similarity_index = similarity_index[:top_n]\n","    # print top similarity values\n","    print('Top cosine similarities are ======>',similarities[0][top_similarity_index])\n","    # get similar questions title\n","    similar_questions = X_train['title'][top_similarity_index]\n","    total_time = (time.time() - start)\n","    print('\\t')\n","    print('Total time ===========> ',total_time)\n","    print('Top 10 similar questions Using Universal sentence encoder')\n","    print('='*100)\n","    return list(similar_questions)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAc4xXsrKwNY","executionInfo":{"status":"ok","timestamp":1604158335971,"user_tz":-330,"elapsed":5322,"user":{"displayName":"sumit patel","photoUrl":"","userId":"08527105377083185844"}},"outputId":"2c9c290e-93b9-41b3-a6c8-a68011b5fd48","colab":{"base_uri":"https://localhost:8080/"}},"source":["query = 'How to make dictionary in python'\n","final_func1(query)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Top cosine similarities are ======> [0.76299614 0.71827483 0.7150197  0.677094   0.66860086 0.66528165\n"," 0.6553011  0.6445547  0.6352596  0.6351328 ]\n","\t\n","Total time ===========>  4.095801830291748\n","Top 10 similar questions Using Universal sentence encoder\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['How to ignore \\\\ before \" in simplejson?',\n"," 'How to convert a list into a dictionary in python',\n"," 'How to convert string to dictionary into python',\n"," 'Python - Unnest List of Dictionaries',\n"," 'How to use python dict in my write order',\n"," 'How to make an OR statement in python?',\n"," 'how to create a dict from two lists in python3',\n"," 'write a dictionary of dictionaries (with unknown size) as a matrix',\n"," 'Python converting a list into a dict with a value of 1 for each key',\n"," 'Python - How to convert a list of dictionaries with tree items?']"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"tX-vNg2cKwJA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qLXt-t9HKv9E"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NrK4FJW9Kv5N"},"source":[""],"execution_count":null,"outputs":[]}]}